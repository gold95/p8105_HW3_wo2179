Homework 3
================
Wuraola Olawole
10/8/2020

``` r
library(tidyverse)
```

    ## -- Attaching packages ------------------------------------------------------------------------------------------- tidyverse 1.3.0 --

    ## v ggplot2 3.3.2     v purrr   0.3.4
    ## v tibble  3.0.3     v dplyr   1.0.2
    ## v tidyr   1.1.2     v stringr 1.4.0
    ## v readr   1.3.1     v forcats 0.5.0

    ## -- Conflicts ---------------------------------------------------------------------------------------------- tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
library(p8105.datasets)
library(viridis)
```

    ## Loading required package: viridisLite

``` r
library(patchwork)
```

# Problem 1

``` r
data("instacart")
```

This dataset contains 1384617 rows and 15 columns.

Observations are the level of items in orders by user. There are user /
order variables – user ID, order ID, order day, and order hour. There
are also item variables – name, aisle, department, and some numeric
codes.

How many aisles, and which are most items from?

``` r
instacart %>% 
    count(aisle) %>% 
    arrange(desc(n))
```

    ## # A tibble: 134 x 2
    ##    aisle                              n
    ##    <chr>                          <int>
    ##  1 fresh vegetables              150609
    ##  2 fresh fruits                  150473
    ##  3 packaged vegetables fruits     78493
    ##  4 yogurt                         55240
    ##  5 packaged cheese                41699
    ##  6 water seltzer sparkling water  36617
    ##  7 milk                           32644
    ##  8 chips pretzels                 31269
    ##  9 soy lactosefree                26240
    ## 10 bread                          23635
    ## # ... with 124 more rows

``` r
instacart %>% 
    count(aisle) %>% 
    filter(n > 10000) %>% 
    mutate(
        aisle = factor(aisle),
        aisle = fct_reorder(aisle, n)
    ) %>% 
    ggplot(aes(x = aisle, y = n)) + 
    geom_point() + 
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

![](p8105_Hw3_wo2179_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->
Let’s make a table\!\!

``` r
instacart %>% 
    filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
    group_by(aisle) %>% 
    count(product_name) %>% 
    mutate(rank = min_rank(desc(n))) %>% 
    filter(rank < 4) %>% 
    arrange(aisle, rank) %>% 
    knitr::kable()
```

| aisle                      | product\_name                                 |    n | rank |
| :------------------------- | :-------------------------------------------- | ---: | ---: |
| baking ingredients         | Light Brown Sugar                             |  499 |    1 |
| baking ingredients         | Pure Baking Soda                              |  387 |    2 |
| baking ingredients         | Cane Sugar                                    |  336 |    3 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |   30 |    1 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |   28 |    2 |
| dog food care              | Small Dog Biscuits                            |   26 |    3 |
| packaged vegetables fruits | Organic Baby Spinach                          | 9784 |    1 |
| packaged vegetables fruits | Organic Raspberries                           | 5546 |    2 |
| packaged vegetables fruits | Organic Blueberries                           | 4966 |    3 |

Apples vs ice cream..

``` r
instacart %>% 
    filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
    group_by(product_name, order_dow) %>% 
    summarize(mean_hour = mean(order_hour_of_day)) %>% 
    pivot_wider(
        names_from = order_dow,
        values_from = mean_hour
    )
```

    ## `summarise()` regrouping output by 'product_name' (override with `.groups` argument)

    ## # A tibble: 2 x 8
    ## # Groups:   product_name [2]
    ##   product_name       `0`   `1`   `2`   `3`   `4`   `5`   `6`
    ##   <chr>            <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
    ## 1 Coffee Ice Cream  13.8  14.3  15.4  15.3  15.2  12.3  13.8
    ## 2 Pink Lady Apples  13.4  11.4  11.7  14.2  11.6  12.8  11.9

# problem 2

## Part a

Read dataset and tidy\!

``` r
accel_df =
          read_csv(
                        "./Data_set/accel_data.csv") %>% 
    janitor::clean_names() %>%
  pivot_longer(activity_1:activity_1440,
                   names_to = "activity", 
                   values_to = "activity_count") %>%
  separate(col = activity, into = c("activity", "minute"), sep = "_") %>%
    select(-activity) %>%
     mutate(
       minute = as.numeric(minute),
       day = as_factor(day), 
        day = fct_relevel(day, "Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"),
       wkday_wkend = recode(day, Sunday = "weekend", Saturday = "weekend", .default = "weekday" ),
       ) %>%
  arrange(week,day)
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   day = col_character()
    ## )

    ## See spec(...) for full column specifications.

``` r
accel_df =
          accel_df %>%
            mutate(
                  day_id = cumsum(!duplicated(accel_df[1:2]))
  )

accel_df
```

    ## # A tibble: 50,400 x 6
    ##     week day_id day    minute activity_count wkday_wkend
    ##    <dbl>  <int> <fct>   <dbl>          <dbl> <fct>      
    ##  1     1      1 Sunday      1              1 weekend    
    ##  2     1      1 Sunday      2              1 weekend    
    ##  3     1      1 Sunday      3              1 weekend    
    ##  4     1      1 Sunday      4              1 weekend    
    ##  5     1      1 Sunday      5              1 weekend    
    ##  6     1      1 Sunday      6              1 weekend    
    ##  7     1      1 Sunday      7              1 weekend    
    ##  8     1      1 Sunday      8              1 weekend    
    ##  9     1      1 Sunday      9              1 weekend    
    ## 10     1      1 Sunday     10              1 weekend    
    ## # ... with 50,390 more rows

The resulting dataset has 50400 rows and 6 columns There are 6 variables
in this dataset. This dataset contains a recorded data of the activity
count of a 63 year old man on an accelerometer over 24 hour period
(measured in minutes) over 7 days and 5 weeks in all. The observations
made in this data corresponds to the activity count per minutes of the
day over 35 days.
